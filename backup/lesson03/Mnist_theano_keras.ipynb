{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End model building process for MNIST\n",
    "\n",
    "This is a complete end-to-end build at MNIST with Theano + Keras + Python 2.7 on Ubuntu 16.04 + GTX 1080 Ti.\n",
    "\n",
    "Using Data Augmentation and Batch Normalization.\n",
    "\n",
    "Note: MNIST is great way to revise basics about CNNs because it's very fast to train (28x28 images) and there are plenty  benchmarks available on best approaches.\n",
    "Also Keras contains a copy of MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "#Create references to important directories we will use over and over\n",
    "#current_dir = os.getcwd()\n",
    "\n",
    "#Allow relative imports to directories above lesson3/\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1080 Ti (CNMeM is disabled, cuDNN 5103)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#Import modules\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function\n",
    "\n",
    "#In Jupyter notebooks, we need to run this command before doing any plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing: add missing color and OneHot\n",
    "\n",
    "MNIST are greyscale images while  Keras expect RGB (so 3 color channels) images so we need to add an empty dimension (the missing \"color channel\") to MNIST to avoid errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.expand_dims(X_test, 1)\n",
    "X_train = np.expand_dims(X_train, 1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we need to *onehot* encode the labels (*y_values*) because they are actual real figures (0,1,2,3 etc), so *Softmax* can approximate the result with a very high value close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examples\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Onehot encoding\n",
    "y_train = onehot(y_train)\n",
    "y_test = onehot(y_test)\n",
    "\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization\n",
    "We normalize the input by substracting the mean and dividing by the Standard Deviation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return (x-mean_px) / std_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Model\n",
    "\n",
    "We need a linear model which needs to:\n",
    "- normalize the input, \n",
    "- flatten it as a simple vector instead of an image,\n",
    "- create a Dense layer with 10 outputs under *Softmax*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lin_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (1, 28, 28)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')    \n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_1 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "lm = get_lin_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 1, 28, 28)     0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 784)           0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 10)            7850        flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Basic Gen without data augmentation\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size = batch_size)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 8s - loss: 0.4287 - acc: 0.8747 - val_loss: 0.2963 - val_acc: 0.9158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3baf845250>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do a first single epoch run with standard params, including lr=0.001\n",
    "lm.fit_generator(batches, batches.n, nb_epoch=1,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 8s - loss: 0.2983 - acc: 0.9139 - val_loss: 0.2810 - val_acc: 0.9193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bc78f64d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit_generator(batches, batches.n, nb_epoch=1,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 9s - loss: 0.2850 - acc: 0.9195 - val_loss: 0.2798 - val_acc: 0.9202\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 10s - loss: 0.2782 - acc: 0.9215 - val_loss: 0.2819 - val_acc: 0.9210\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s - loss: 0.2723 - acc: 0.9235 - val_loss: 0.2852 - val_acc: 0.9210\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 8s - loss: 0.2689 - acc: 0.9248 - val_loss: 0.2789 - val_acc: 0.9202\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s - loss: 0.2664 - acc: 0.9260 - val_loss: 0.2788 - val_acc: 0.9218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bbb639190>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit_generator(batches, batches.n, nb_epoch=5,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Single dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's add one hidden layer fully-connected, like what people called \"Neural Networks\" in the 80-90's.\n",
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape = (1, 28, 28)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')    \n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_2 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "fc = get_fc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 10s - loss: 0.1951 - acc: 0.9400 - val_loss: 0.1106 - val_acc: 0.9647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b9f526c50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And same routine as before\n",
    "fc.fit_generator(batches, batches.n, nb_epoch=1,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 10s - loss: 0.0828 - acc: 0.9744 - val_loss: 0.0806 - val_acc: 0.9739\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 10s - loss: 0.0574 - acc: 0.9817 - val_loss: 0.0802 - val_acc: 0.9762\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s - loss: 0.0431 - acc: 0.9863 - val_loss: 0.0790 - val_acc: 0.9767\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s - loss: 0.0342 - acc: 0.9886 - val_loss: 0.0800 - val_acc: 0.9767\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 9s - loss: 0.0300 - acc: 0.9901 - val_loss: 0.0634 - val_acc: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b9e51bc10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.fit_generator(batches, batches.n, nb_epoch=6,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 9s - loss: 0.0232 - acc: 0.9928 - val_loss: 0.0836 - val_acc: 0.9782\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s - loss: 0.0222 - acc: 0.9927 - val_loss: 0.0824 - val_acc: 0.9809\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s - loss: 0.0187 - acc: 0.9937 - val_loss: 0.0764 - val_acc: 0.9813\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s - loss: 0.0185 - acc: 0.9940 - val_loss: 0.0840 - val_acc: 0.9807\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 9s - loss: 0.0161 - acc: 0.9950 - val_loss: 0.0857 - val_acc: 0.9813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b9e51bb50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.fit_generator(batches, batches.n, nb_epoch=8,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Basic 'VGG-style' CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')        \n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_3 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 16s - loss: 0.1152 - acc: 0.9642 - val_loss: 0.0321 - val_acc: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b9c9e33d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And same routine as before\n",
    "model.fit_generator(batches, batches.n, nb_epoch=1,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 15s - loss: 0.0346 - acc: 0.9894 - val_loss: 0.0242 - val_acc: 0.9925\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 15s - loss: 0.0246 - acc: 0.9923 - val_loss: 0.0269 - val_acc: 0.9925\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 15s - loss: 0.0185 - acc: 0.9946 - val_loss: 0.0229 - val_acc: 0.9930\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 16s - loss: 0.0173 - acc: 0.9945 - val_loss: 0.0291 - val_acc: 0.9921\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 15s - loss: 0.0126 - acc: 0.9959 - val_loss: 0.0341 - val_acc: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b9287cb50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.1\n",
    "model.fit_generator(batches, batches.n, nb_epoch=6,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 15s - loss: 0.0114 - acc: 0.9967 - val_loss: 0.0267 - val_acc: 0.9930\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 15s - loss: 0.0099 - acc: 0.9970 - val_loss: 0.0260 - val_acc: 0.9947\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 15s - loss: 0.0084 - acc: 0.9973 - val_loss: 0.0469 - val_acc: 0.9892\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 15s - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0260 - val_acc: 0.9929\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 15s - loss: 0.0068 - acc: 0.9979 - val_loss: 0.0234 - val_acc: 0.9938\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 15s - loss: 0.0072 - acc: 0.9977 - val_loss: 0.0318 - val_acc: 0.9921\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 15s - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0301 - val_acc: 0.9945\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0071 - acc: 0.9976 - val_loss: 0.0354 - val_acc: 0.9929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b9287c590>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.01\n",
    "model.fit_generator(batches, batches.n, nb_epoch=8,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With lr=0.01, we see a drop in val_acc 0.9922 over train_acc:0.9979 so we are now clearly overfitting compared to lr=0.1\n",
    "\n",
    "#### Which is great news: we now know we have a model which is complex enough to handle our data.\n",
    "#### \"*Start by overfitting* \" said Jeremy Howard, then move to 5-steps dance...\n",
    "\n",
    "##### Recall on 5-steps to reduce overfitting:\n",
    "    1. Add more data (not always possible, e.g. Kaggle competitions)\n",
    "    2. Use Data Augmentation (duplicate+tweak the images)\n",
    "    3. Use architectures that generalize well\n",
    "    4. Add regularization via Batch Normalization\n",
    "    5. Reduce architecture complexity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_4 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://keras.io/preprocessing/image/#imagedatagenerator\n",
    "gen = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, height_shift_range=0.08,\n",
    "                               zoom_range=0.08, shear_range=0.3) #, channel_shift_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size = batch_size)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 17s - loss: 0.1816 - acc: 0.9424 - val_loss: 0.0605 - val_acc: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bb9cc4190>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And same routine as before\n",
    "model.fit_generator(batches, batches.n, nb_epoch=1,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 17s - loss: 0.0626 - acc: 0.9804 - val_loss: 0.0492 - val_acc: 0.9838\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 17s - loss: 0.0481 - acc: 0.9852 - val_loss: 0.0449 - val_acc: 0.9854\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 17s - loss: 0.0420 - acc: 0.9865 - val_loss: 0.0306 - val_acc: 0.9897\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 17s - loss: 0.0368 - acc: 0.9887 - val_loss: 0.0413 - val_acc: 0.9863\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0357 - acc: 0.9894 - val_loss: 0.0362 - val_acc: 0.9880\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0317 - acc: 0.9904 - val_loss: 0.0386 - val_acc: 0.9881\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 17s - loss: 0.0302 - acc: 0.9905 - val_loss: 0.0334 - val_acc: 0.9901\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 17s - loss: 0.0287 - acc: 0.9908 - val_loss: 0.0394 - val_acc: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bb9592e90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.1\n",
    "model.fit_generator(batches, batches.n, nb_epoch=6,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0253 - acc: 0.9919 - val_loss: 0.0278 - val_acc: 0.9906\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0248 - acc: 0.9920 - val_loss: 0.0278 - val_acc: 0.9914\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 17s - loss: 0.0231 - acc: 0.9924 - val_loss: 0.0349 - val_acc: 0.9899\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0229 - acc: 0.9925 - val_loss: 0.0356 - val_acc: 0.9894\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 17s - loss: 0.0214 - acc: 0.9932 - val_loss: 0.0340 - val_acc: 0.9903\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0225 - acc: 0.9928 - val_loss: 0.0303 - val_acc: 0.9899\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0201 - acc: 0.9942 - val_loss: 0.0239 - val_acc: 0.9915\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 17s - loss: 0.0213 - acc: 0.9941 - val_loss: 0.0275 - val_acc: 0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bb9592750>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.01\n",
    "model.fit_generator(batches, batches.n, nb_epoch=8,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0183 - acc: 0.9941 - val_loss: 0.0291 - val_acc: 0.9919\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0203 - acc: 0.9934 - val_loss: 0.0214 - val_acc: 0.9938\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0185 - acc: 0.9942 - val_loss: 0.0354 - val_acc: 0.9903\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 18s - loss: 0.0183 - acc: 0.9944 - val_loss: 0.0277 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 17s - loss: 0.0175 - acc: 0.9943 - val_loss: 0.0312 - val_acc: 0.9923\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 17s - loss: 0.0182 - acc: 0.9942 - val_loss: 0.0223 - val_acc: 0.9941\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 17s - loss: 0.0176 - acc: 0.9944 - val_loss: 0.0278 - val_acc: 0.9913\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 17s - loss: 0.0161 - acc: 0.9946 - val_loss: 0.0234 - val_acc: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bb9592e10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.001\n",
    "model.fit_generator(batches, batches.n, nb_epoch=10,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# BatchNormalization + Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_bn():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dense(10, activation='softmax')        \n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_5 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = get_model_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 28s - loss: 0.1439 - acc: 0.9555 - val_loss: 0.0624 - val_acc: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bb7668390>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And same routine as before\n",
    "model.fit_generator(batches, batches.n, nb_epoch=1,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 26s - loss: 0.0615 - acc: 0.9811 - val_loss: 0.0465 - val_acc: 0.9841\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 27s - loss: 0.0531 - acc: 0.9832 - val_loss: 0.0559 - val_acc: 0.9845\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 28s - loss: 0.0467 - acc: 0.9851 - val_loss: 0.0422 - val_acc: 0.9862\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 27s - loss: 0.0429 - acc: 0.9864 - val_loss: 0.0333 - val_acc: 0.9898\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 30s - loss: 0.0373 - acc: 0.9879 - val_loss: 0.0413 - val_acc: 0.9877\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 26s - loss: 0.0356 - acc: 0.9886 - val_loss: 0.0334 - val_acc: 0.9892\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 30s - loss: 0.0340 - acc: 0.9892 - val_loss: 0.0341 - val_acc: 0.9884\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 28s - loss: 0.0311 - acc: 0.9898 - val_loss: 0.0242 - val_acc: 0.9923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3baf8f4f90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.1\n",
    "model.fit_generator(batches, batches.n, nb_epoch=6,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 26s - loss: 0.0315 - acc: 0.9897 - val_loss: 0.0278 - val_acc: 0.9899\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 26s - loss: 0.0297 - acc: 0.9909 - val_loss: 0.0300 - val_acc: 0.9903\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 26s - loss: 0.0276 - acc: 0.9914 - val_loss: 0.0241 - val_acc: 0.9914\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 26s - loss: 0.0255 - acc: 0.9923 - val_loss: 0.0247 - val_acc: 0.9916\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 26s - loss: 0.0241 - acc: 0.9922 - val_loss: 0.0272 - val_acc: 0.9905\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 26s - loss: 0.0245 - acc: 0.9922 - val_loss: 0.0222 - val_acc: 0.9935\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 26s - loss: 0.0226 - acc: 0.9931 - val_loss: 0.0220 - val_acc: 0.9935\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 26s - loss: 0.0231 - acc: 0.9927 - val_loss: 0.0323 - val_acc: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bb95aa050>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.01\n",
    "model.fit_generator(batches, batches.n, nb_epoch=8,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 28s - loss: 0.0175 - acc: 0.9942 - val_loss: 0.0225 - val_acc: 0.9926\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 27s - loss: 0.0157 - acc: 0.9947 - val_loss: 0.0258 - val_acc: 0.9913\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 28s - loss: 0.0184 - acc: 0.9940 - val_loss: 0.0202 - val_acc: 0.9933\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 28s - loss: 0.0179 - acc: 0.9939 - val_loss: 0.0226 - val_acc: 0.9927\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 27s - loss: 0.0166 - acc: 0.9950 - val_loss: 0.0270 - val_acc: 0.9927\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 27s - loss: 0.0169 - acc: 0.9945 - val_loss: 0.0267 - val_acc: 0.9924\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 27s - loss: 0.0152 - acc: 0.9952 - val_loss: 0.0177 - val_acc: 0.9940\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 27s - loss: 0.0149 - acc: 0.9953 - val_loss: 0.0231 - val_acc: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bb9273090>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.001\n",
    "model.fit_generator(batches, batches.n, nb_epoch=10,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# BatchNormalization + Dropout + Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_bn_do():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')        \n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_7 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = get_model_bn_do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 27s - loss: 0.2250 - acc: 0.9322 - val_loss: 0.0729 - val_acc: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b8e32a250>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And same routine as before\n",
    "model.fit_generator(batches, batches.n, nb_epoch=1,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 27s - loss: 0.0917 - acc: 0.9727 - val_loss: 0.0503 - val_acc: 0.9827\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 27s - loss: 0.0747 - acc: 0.9772 - val_loss: 0.0484 - val_acc: 0.9838\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 27s - loss: 0.0672 - acc: 0.9790 - val_loss: 0.0431 - val_acc: 0.9863\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 27s - loss: 0.0615 - acc: 0.9812 - val_loss: 0.0355 - val_acc: 0.9886\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 28s - loss: 0.0568 - acc: 0.9824 - val_loss: 0.0444 - val_acc: 0.9853\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 27s - loss: 0.0524 - acc: 0.9844 - val_loss: 0.0330 - val_acc: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b8ed3c510>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.1\n",
    "model.fit_generator(batches, batches.n, nb_epoch=6,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 26s - loss: 0.0488 - acc: 0.9850 - val_loss: 0.0388 - val_acc: 0.9876\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 27s - loss: 0.0478 - acc: 0.9855 - val_loss: 0.0298 - val_acc: 0.9904\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 26s - loss: 0.0475 - acc: 0.9853 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 27s - loss: 0.0442 - acc: 0.9860 - val_loss: 0.0346 - val_acc: 0.9888\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 27s - loss: 0.0404 - acc: 0.9874 - val_loss: 0.0284 - val_acc: 0.9912\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 27s - loss: 0.0398 - acc: 0.9880 - val_loss: 0.0251 - val_acc: 0.9915\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 28s - loss: 0.0386 - acc: 0.9883 - val_loss: 0.0273 - val_acc: 0.9910\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 27s - loss: 0.0377 - acc: 0.9884 - val_loss: 0.0255 - val_acc: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b8ed95ed0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.01\n",
    "model.fit_generator(batches, batches.n, nb_epoch=8,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 26s - loss: 0.0347 - acc: 0.9891 - val_loss: 0.0310 - val_acc: 0.9903\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 26s - loss: 0.0361 - acc: 0.9892 - val_loss: 0.0238 - val_acc: 0.9931\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 28s - loss: 0.0359 - acc: 0.9894 - val_loss: 0.0221 - val_acc: 0.9931\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 26s - loss: 0.0317 - acc: 0.9905 - val_loss: 0.0262 - val_acc: 0.9920\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 27s - loss: 0.0322 - acc: 0.9903 - val_loss: 0.0268 - val_acc: 0.9926\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 27s - loss: 0.0301 - acc: 0.9905 - val_loss: 0.0229 - val_acc: 0.9926\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 28s - loss: 0.0306 - acc: 0.9909 - val_loss: 0.0262 - val_acc: 0.9917\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 26s - loss: 0.0305 - acc: 0.9910 - val_loss: 0.0257 - val_acc: 0.9927\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 26s - loss: 0.0290 - acc: 0.9914 - val_loss: 0.0265 - val_acc: 0.9926\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 27s - loss: 0.0284 - acc: 0.9912 - val_loss: 0.0265 - val_acc: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b8ec26110>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.001\n",
    "model.fit_generator(batches, batches.n, nb_epoch=10,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model():\n",
    "    model = get_model_bn_do()\n",
    "    \n",
    "    model.fit_generator(batches, batches.n, nb_epoch=1, verbose=0,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    \n",
    "    model.optimizer.lr = 0.1\n",
    "    model.fit_generator(batches, batches.n, nb_epoch=6, verbose=0,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    \n",
    "    model.optimizer.lr = 0.01\n",
    "    model.fit_generator(batches, batches.n, nb_epoch=8, verbose=0,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    \n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, batches.n, nb_epoch=10, verbose=0,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    \n",
    "    return model\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_8 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/eric/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_9 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/eric/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_10 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/eric/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_11 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/eric/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_12 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/eric/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_13 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "models = [fit_model() for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,m in enumerate(models):\n",
    "    m.save_weights('cbb-mnist-' + str(i) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9472/10000 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "evals = np.array([m.evaluate(X_test, y_test, batch_size = 256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0135,  0.9956])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(X_test, batch_size = 256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 10000, 10)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.9969000220298767, dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.metrics.categorical_accuracy(y_test, avg_preds).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
